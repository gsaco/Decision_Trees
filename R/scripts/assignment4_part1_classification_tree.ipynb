{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 - Part 1: Predicting Heart Disease Using a Classification Tree (R)\n",
    "\n",
    "This notebook implements a classification tree model to predict whether a person is likely to have heart disease using R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando paquete requerido: ggplot2\n",
      "\n",
      "Cargando paquete requerido: lattice\n",
      "\n",
      "\n",
      "Adjuntando el paquete: ‘dplyr’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load necessary libraries\n",
    "library(rpart)\n",
    "library(rpart.plot)\n",
    "library(caret)\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "set.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Data Cleaning (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: 303 14 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 14</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>age</th><th scope=col>sex</th><th scope=col>cp</th><th scope=col>restbp</th><th scope=col>chol</th><th scope=col>fbs</th><th scope=col>restecg</th><th scope=col>thalach</th><th scope=col>exang</th><th scope=col>oldpeak</th><th scope=col>slope</th><th scope=col>ca</th><th scope=col>thal</th><th scope=col>hd</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>63</td><td>1</td><td>1</td><td>145</td><td>233</td><td>1</td><td>2</td><td>150</td><td>0</td><td>2.3</td><td>3</td><td>0</td><td>6</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>67</td><td>1</td><td>4</td><td>160</td><td>286</td><td>0</td><td>2</td><td>108</td><td>1</td><td>1.5</td><td>2</td><td>3</td><td>3</td><td>2</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>67</td><td>1</td><td>4</td><td>120</td><td>229</td><td>0</td><td>2</td><td>129</td><td>1</td><td>2.6</td><td>2</td><td>2</td><td>7</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>37</td><td>1</td><td>3</td><td>130</td><td>250</td><td>0</td><td>0</td><td>187</td><td>0</td><td>3.5</td><td>3</td><td>0</td><td>3</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>41</td><td>0</td><td>2</td><td>130</td><td>204</td><td>0</td><td>2</td><td>172</td><td>0</td><td>1.4</td><td>1</td><td>0</td><td>3</td><td>0</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>56</td><td>1</td><td>2</td><td>120</td><td>236</td><td>0</td><td>0</td><td>178</td><td>0</td><td>0.8</td><td>1</td><td>0</td><td>3</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 14\n",
       "\\begin{tabular}{r|llllllllllllll}\n",
       "  & age & sex & cp & restbp & chol & fbs & restecg & thalach & exang & oldpeak & slope & ca & thal & hd\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <int>\\\\\n",
       "\\hline\n",
       "\t1 & 63 & 1 & 1 & 145 & 233 & 1 & 2 & 150 & 0 & 2.3 & 3 & 0 & 6 & 0\\\\\n",
       "\t2 & 67 & 1 & 4 & 160 & 286 & 0 & 2 & 108 & 1 & 1.5 & 2 & 3 & 3 & 2\\\\\n",
       "\t3 & 67 & 1 & 4 & 120 & 229 & 0 & 2 & 129 & 1 & 2.6 & 2 & 2 & 7 & 1\\\\\n",
       "\t4 & 37 & 1 & 3 & 130 & 250 & 0 & 0 & 187 & 0 & 3.5 & 3 & 0 & 3 & 0\\\\\n",
       "\t5 & 41 & 0 & 2 & 130 & 204 & 0 & 2 & 172 & 0 & 1.4 & 1 & 0 & 3 & 0\\\\\n",
       "\t6 & 56 & 1 & 2 & 120 & 236 & 0 & 0 & 178 & 0 & 0.8 & 1 & 0 & 3 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 14\n",
       "\n",
       "| <!--/--> | age &lt;dbl&gt; | sex &lt;dbl&gt; | cp &lt;dbl&gt; | restbp &lt;dbl&gt; | chol &lt;dbl&gt; | fbs &lt;dbl&gt; | restecg &lt;dbl&gt; | thalach &lt;dbl&gt; | exang &lt;dbl&gt; | oldpeak &lt;dbl&gt; | slope &lt;dbl&gt; | ca &lt;dbl&gt; | thal &lt;dbl&gt; | hd &lt;int&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 63 | 1 | 1 | 145 | 233 | 1 | 2 | 150 | 0 | 2.3 | 3 | 0 | 6 | 0 |\n",
       "| 2 | 67 | 1 | 4 | 160 | 286 | 0 | 2 | 108 | 1 | 1.5 | 2 | 3 | 3 | 2 |\n",
       "| 3 | 67 | 1 | 4 | 120 | 229 | 0 | 2 | 129 | 1 | 2.6 | 2 | 2 | 7 | 1 |\n",
       "| 4 | 37 | 1 | 3 | 130 | 250 | 0 | 0 | 187 | 0 | 3.5 | 3 | 0 | 3 | 0 |\n",
       "| 5 | 41 | 0 | 2 | 130 | 204 | 0 | 2 | 172 | 0 | 1.4 | 1 | 0 | 3 | 0 |\n",
       "| 6 | 56 | 1 | 2 | 120 | 236 | 0 | 0 | 178 | 0 | 0.8 | 1 | 0 | 3 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  age sex cp restbp chol fbs restecg thalach exang oldpeak slope ca thal hd\n",
       "1 63  1   1  145    233  1   2       150     0     2.3     3     0  6    0 \n",
       "2 67  1   4  160    286  0   2       108     1     1.5     2     3  3    2 \n",
       "3 67  1   4  120    229  0   2       129     1     2.6     2     2  7    1 \n",
       "4 37  1   3  130    250  0   0       187     0     3.5     3     0  3    0 \n",
       "5 41  0   2  130    204  0   2       172     0     1.4     1     0  3    0 \n",
       "6 56  1   2  120    236  0   0       178     0     0.8     1     0  3    0 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "column_names <- c('age', 'sex', 'cp', 'restbp', 'chol', 'fbs', 'restecg', \n",
    "                  'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'hd')\n",
    "\n",
    "df <- read.csv('../input/processed.cleveland.data', \n",
    "               header = FALSE,\n",
    "               col.names = column_names,\n",
    "               na.strings = '?')\n",
    "\n",
    "cat(\"Original dataset shape:\", dim(df), \"\\n\")\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>age</dt><dd>0</dd><dt>sex</dt><dd>0</dd><dt>cp</dt><dd>0</dd><dt>restbp</dt><dd>0</dd><dt>chol</dt><dd>0</dd><dt>fbs</dt><dd>0</dd><dt>restecg</dt><dd>0</dd><dt>thalach</dt><dd>0</dd><dt>exang</dt><dd>0</dd><dt>oldpeak</dt><dd>0</dd><dt>slope</dt><dd>0</dd><dt>ca</dt><dd>4</dd><dt>thal</dt><dd>2</dd><dt>hd</dt><dd>0</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[age] 0\n",
       "\\item[sex] 0\n",
       "\\item[cp] 0\n",
       "\\item[restbp] 0\n",
       "\\item[chol] 0\n",
       "\\item[fbs] 0\n",
       "\\item[restecg] 0\n",
       "\\item[thalach] 0\n",
       "\\item[exang] 0\n",
       "\\item[oldpeak] 0\n",
       "\\item[slope] 0\n",
       "\\item[ca] 4\n",
       "\\item[thal] 2\n",
       "\\item[hd] 0\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "age\n",
       ":   0sex\n",
       ":   0cp\n",
       ":   0restbp\n",
       ":   0chol\n",
       ":   0fbs\n",
       ":   0restecg\n",
       ":   0thalach\n",
       ":   0exang\n",
       ":   0oldpeak\n",
       ":   0slope\n",
       ":   0ca\n",
       ":   4thal\n",
       ":   2hd\n",
       ":   0\n",
       "\n"
      ],
      "text/plain": [
       "    age     sex      cp  restbp    chol     fbs restecg thalach   exang oldpeak \n",
       "      0       0       0       0       0       0       0       0       0       0 \n",
       "  slope      ca    thal      hd \n",
       "      0       4       2       0 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset shape after removing missing values: 297 14 \n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "cat(\"Missing values per column:\\n\")\n",
    "colSums(is.na(df))\n",
    "\n",
    "# Remove missing values\n",
    "df <- na.omit(df)\n",
    "cat(\"\\nDataset shape after removing missing values:\", dim(df), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of target variable:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   1 \n",
       "160 137 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create binary variable y (1 if heart disease, 0 otherwise)\n",
    "df$y <- ifelse(df$hd > 0, 1, 0)\n",
    "cat(\"Distribution of target variable:\\n\")\n",
    "table(df$y)\n",
    "\n",
    "# Remove the original hd column\n",
    "df$hd <- NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset structure:\n",
      "'data.frame':\t297 obs. of  14 variables:\n",
      " $ age    : num  63 67 67 37 41 56 62 57 63 53 ...\n",
      " $ sex    : Factor w/ 2 levels \"0\",\"1\": 2 2 2 2 1 2 1 1 2 2 ...\n",
      " $ cp     : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 1 4 4 3 2 2 4 4 4 4 ...\n",
      " $ restbp : num  145 160 120 130 130 120 140 120 130 140 ...\n",
      " $ chol   : num  233 286 229 250 204 236 268 354 254 203 ...\n",
      " $ fbs    : Factor w/ 2 levels \"0\",\"1\": 2 1 1 1 1 1 1 1 1 2 ...\n",
      " $ restecg: Factor w/ 3 levels \"0\",\"1\",\"2\": 3 3 3 1 3 1 3 1 3 3 ...\n",
      " $ thalach: num  150 108 129 187 172 178 160 163 147 155 ...\n",
      " $ exang  : Factor w/ 2 levels \"0\",\"1\": 1 2 2 1 1 1 1 2 1 2 ...\n",
      " $ oldpeak: num  2.3 1.5 2.6 3.5 1.4 0.8 3.6 0.6 1.4 3.1 ...\n",
      " $ slope  : Factor w/ 3 levels \"1\",\"2\",\"3\": 3 2 2 3 1 1 3 1 2 3 ...\n",
      " $ ca     : Factor w/ 4 levels \"0\",\"1\",\"2\",\"3\": 1 4 3 1 1 1 3 1 2 1 ...\n",
      " $ thal   : Factor w/ 3 levels \"3\",\"6\",\"7\": 2 1 3 1 1 1 1 1 3 3 ...\n",
      " $ y      : Factor w/ 2 levels \"0\",\"1\": 1 2 2 1 1 1 2 1 2 2 ...\n",
      " - attr(*, \"na.action\")= 'omit' Named int [1:6] 88 167 193 267 288 303\n",
      "  ..- attr(*, \"names\")= chr [1:6] \"88\" \"167\" \"193\" \"267\" ...\n"
     ]
    }
   ],
   "source": [
    "# Convert categorical variables to factors\n",
    "categorical_vars <- c('sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal')\n",
    "df[categorical_vars] <- lapply(df[categorical_vars], as.factor)\n",
    "\n",
    "# Convert y to factor for classification\n",
    "df$y <- as.factor(df$y)\n",
    "\n",
    "cat(\"Dataset structure:\\n\")\n",
    "str(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data Analysis (8 points)\n",
    "\n",
    "### (1 point) Split data and plot classification tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 208 \n",
      "Test set size: 89 \n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "set.seed(123)\n",
    "train_index <- createDataPartition(df$y, p = 0.7, list = FALSE)\n",
    "train_data <- df[train_index, ]\n",
    "test_data <- df[-train_index, ]\n",
    "\n",
    "cat(\"Training set size:\", nrow(train_data), \"\\n\")\n",
    "cat(\"Test set size:\", nrow(test_data), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>pdf:</strong> 2"
      ],
      "text/latex": [
       "\\textbf{pdf:} 2"
      ],
      "text/markdown": [
       "**pdf:** 2"
      ],
      "text/plain": [
       "pdf \n",
       "  2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree complexity parameters:\n",
      "\n",
      "Classification tree:\n",
      "rpart(formula = y ~ ., data = train_data, method = \"class\")\n",
      "\n",
      "Variables actually used in tree construction:\n",
      "[1] ca      chol    cp      oldpeak thal    thalach\n",
      "\n",
      "Root node error: 96/208 = 0.46154\n",
      "\n",
      "n= 208 \n",
      "\n",
      "        CP nsplit rel error  xerror     xstd\n",
      "1 0.500000      0   1.00000 1.00000 0.074893\n",
      "2 0.052083      1   0.50000 0.50000 0.063296\n",
      "3 0.041667      3   0.39583 0.52083 0.064196\n",
      "4 0.020833      4   0.35417 0.54167 0.065052\n",
      "5 0.010417      5   0.33333 0.53125 0.064630\n",
      "6 0.010000      7   0.31250 0.55208 0.065464\n"
     ]
    }
   ],
   "source": [
    "# Train a classification tree without pruning\n",
    "tree_model <- rpart(y ~ ., data = train_data, method = \"class\")\n",
    "\n",
    "# Plot the classification tree\n",
    "png('../output/classification_tree_before_pruning_R.png', width = 1200, height = 800)\n",
    "rpart.plot(tree_model, main = \"Classification Tree (Before Pruning)\",\n",
    "           extra = 104, box.palette = \"RdBu\", shadow.col = \"gray\")\n",
    "dev.off()\n",
    "\n",
    "# Display tree info\n",
    "cat(\"Tree complexity parameters:\\n\")\n",
    "printcp(tree_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2 points) Plot confusion matrix and interpret results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix and Statistics\n",
      "\n",
      "         Actual\n",
      "Predicted  0  1\n",
      "        0 34  5\n",
      "        1 14 36\n",
      "                                          \n",
      "               Accuracy : 0.7865          \n",
      "                 95% CI : (0.6869, 0.8663)\n",
      "    No Information Rate : 0.5393          \n",
      "    P-Value [Acc > NIR] : 1.112e-06       \n",
      "                                          \n",
      "                  Kappa : 0.5771          \n",
      "                                          \n",
      " Mcnemar's Test P-Value : 0.06646         \n",
      "                                          \n",
      "            Sensitivity : 0.7083          \n",
      "            Specificity : 0.8780          \n",
      "         Pos Pred Value : 0.8718          \n",
      "         Neg Pred Value : 0.7200          \n",
      "             Prevalence : 0.5393          \n",
      "         Detection Rate : 0.3820          \n",
      "   Detection Prevalence : 0.4382          \n",
      "      Balanced Accuracy : 0.7932          \n",
      "                                          \n",
      "       'Positive' Class : 0               \n",
      "                                          \n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test set\n",
    "predictions <- predict(tree_model, test_data, type = \"class\")\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm <- confusionMatrix(predictions, test_data$y, \n",
    "                      dnn = c(\"Predicted\", \"Actual\"))\n",
    "print(cm)\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm_table <- as.data.frame(cm$table)\n",
    "colnames(cm_table) <- c(\"Predicted\", \"Actual\", \"Freq\")\n",
    "cm_table$Predicted <- ifelse(cm_table$Predicted == \"0\", \"Does not have HD\", \"Has HD\")\n",
    "cm_table$Actual <- ifelse(cm_table$Actual == \"0\", \"Does not have HD\", \"Has HD\")\n",
    "\n",
    "p <- ggplot(cm_table, aes(x = Predicted, y = Actual, fill = Freq)) +\n",
    "  geom_tile() +\n",
    "  geom_text(aes(label = Freq), size = 8) +\n",
    "  scale_fill_gradient(low = \"white\", high = \"steelblue\") +\n",
    "  labs(title = \"Confusion Matrix (Before Pruning)\",\n",
    "       x = \"Predicted Label\", y = \"True Label\") +\n",
    "  theme_minimal() +\n",
    "  theme(text = element_text(size = 14))\n",
    "\n",
    "ggsave('../output/confusion_matrix_before_pruning_R.png', p, width = 8, height = 6, dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation (Before Pruning):**\n",
    "\n",
    "Based on our classification tree model results:\n",
    "\n",
    "- **Dataset**: After cleaning, we have 297 samples (160 without heart disease, 137 with heart disease)\n",
    "- **Split**: 208 training samples and 89 test samples (70-30 split)\n",
    "\n",
    "**Confusion Matrix Results:**\n",
    "- **True Negatives (TN)**: 34 - correctly predicted individuals without heart disease\n",
    "- **True Positives (TP)**: 36 - correctly predicted individuals with heart disease  \n",
    "- **False Positives (FP)**: 14 - incorrectly predicted as having heart disease (Type I error)\n",
    "- **False Negatives (FN)**: 5 - incorrectly predicted as not having heart disease (Type II error, more concerning in medical diagnosis)\n",
    "\n",
    "**Model Performance:**\n",
    "- **Accuracy**: 78.65% - the model correctly classifies about 79% of cases\n",
    "- **Sensitivity (Recall)**: 70.83% - ability to correctly identify those without heart disease\n",
    "- **Specificity**: 87.80% - ability to correctly identify those with heart disease\n",
    "- **Positive Predictive Value**: 87.18% - when predicting no heart disease, it's correct 87% of the time\n",
    "- **Kappa**: 0.5771 - moderate agreement beyond chance\n",
    "\n",
    "The model shows good specificity but could improve sensitivity. The relatively high number of false positives (14) compared to false negatives (5) suggests the model is slightly conservative in predicting heart disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.5 points) Fix overfitting using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of alpha values: 50 \n",
      "Alpha range: 4.539993e-05 to 0.05 \n"
     ]
    }
   ],
   "source": [
    "# Generate 50 values of alpha (cp in rpart) equally spaced on logarithmic scale\n",
    "alpha_values <- exp(seq(log(exp(-10)), log(0.05), length.out = 50))\n",
    "\n",
    "cat(\"Number of alpha values:\", length(alpha_values), \"\\n\")\n",
    "cat(\"Alpha range:\", min(alpha_values), \"to\", max(alpha_values), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha: 0.0001643517 \n",
      "Optimal cross-validation accuracy: 0.8076923 \n"
     ]
    }
   ],
   "source": [
    "# Perform 4-fold cross-validation for each alpha\n",
    "set.seed(123)\n",
    "mean_accuracies <- numeric(length(alpha_values))\n",
    "\n",
    "for (i in seq_along(alpha_values)) {\n",
    "  # Create folds\n",
    "  folds <- createFolds(train_data$y, k = 4)\n",
    "  accuracies <- numeric(4)\n",
    "  \n",
    "  for (j in 1:4) {\n",
    "    # Split into train and validation\n",
    "    val_idx <- folds[[j]]\n",
    "    train_cv <- train_data[-val_idx, ]\n",
    "    val_cv <- train_data[val_idx, ]\n",
    "    \n",
    "    # Train model with current alpha\n",
    "    model_cv <- rpart(y ~ ., data = train_cv, method = \"class\",\n",
    "                      control = rpart.control(cp = alpha_values[i]))\n",
    "    \n",
    "    # Predict and calculate accuracy\n",
    "    pred_cv <- predict(model_cv, val_cv, type = \"class\")\n",
    "    accuracies[j] <- mean(pred_cv == val_cv$y)\n",
    "  }\n",
    "  \n",
    "  mean_accuracies[i] <- mean(accuracies)\n",
    "}\n",
    "\n",
    "# Find optimal alpha\n",
    "optimal_idx <- which.max(mean_accuracies)\n",
    "optimal_alpha <- alpha_values[optimal_idx]\n",
    "optimal_accuracy <- mean_accuracies[optimal_idx]\n",
    "\n",
    "cat(\"Optimal alpha:\", optimal_alpha, \"\\n\")\n",
    "cat(\"Optimal cross-validation accuracy:\", optimal_accuracy, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.5 points) Plot Inaccuracy Rate vs Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“\u001b[1m\u001b[22mUsing `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n",
      "\u001b[36mℹ\u001b[39m Please use `linewidth` instead.”\n"
     ]
    }
   ],
   "source": [
    "# Calculate inaccuracy rate\n",
    "inaccuracy_rates <- 1 - mean_accuracies\n",
    "\n",
    "# Create data frame for plotting\n",
    "plot_df <- data.frame(alpha = alpha_values, inaccuracy = inaccuracy_rates)\n",
    "\n",
    "# Plot Inaccuracy Rate vs Alpha\n",
    "p <- ggplot(plot_df, aes(x = alpha, y = inaccuracy)) +\n",
    "  geom_line() +\n",
    "  geom_point(size = 2) +\n",
    "  geom_vline(xintercept = optimal_alpha, color = \"red\", linetype = \"dashed\",\n",
    "             size = 1) +\n",
    "  annotate(\"text\", x = optimal_alpha * 2, y = max(inaccuracy_rates) * 0.9,\n",
    "           label = paste(\"Optimal α =\", round(optimal_alpha, 6)), color = \"red\") +\n",
    "  scale_x_log10() +\n",
    "  labs(title = \"Inaccuracy Rate vs Alpha\",\n",
    "       x = \"Alpha (log scale)\",\n",
    "       y = \"Inaccuracy Rate (1 - Accuracy)\") +\n",
    "  theme_minimal() +\n",
    "  theme(text = element_text(size = 12))\n",
    "\n",
    "ggsave('../output/inaccuracy_vs_alpha_R.png', p, width = 10, height = 6, dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2 points) Plot pruned tree and confusion matrix with optimal alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>pdf:</strong> 2"
      ],
      "text/latex": [
       "\\textbf{pdf:} 2"
      ],
      "text/markdown": [
       "**pdf:** 2"
      ],
      "text/plain": [
       "pdf \n",
       "  2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned tree complexity parameters:\n",
      "\n",
      "Classification tree:\n",
      "rpart(formula = y ~ ., data = train_data, method = \"class\", control = rpart.control(cp = optimal_alpha))\n",
      "\n",
      "Variables actually used in tree construction:\n",
      "[1] ca      chol    cp      oldpeak thal    thalach\n",
      "\n",
      "Root node error: 96/208 = 0.46154\n",
      "\n",
      "n= 208 \n",
      "\n",
      "          CP nsplit rel error  xerror     xstd\n",
      "1 0.50000000      0   1.00000 1.00000 0.074893\n",
      "2 0.05208333      1   0.50000 0.55208 0.065464\n",
      "3 0.04166667      3   0.39583 0.54167 0.065052\n",
      "4 0.02083333      4   0.35417 0.58333 0.066637\n",
      "5 0.01041667      5   0.33333 0.59375 0.067007\n",
      "6 0.00016435      7   0.31250 0.62500 0.068062\n"
     ]
    }
   ],
   "source": [
    "# Train a classification tree with optimal alpha\n",
    "tree_pruned <- rpart(y ~ ., data = train_data, method = \"class\",\n",
    "                     control = rpart.control(cp = optimal_alpha))\n",
    "\n",
    "# Plot the pruned classification tree\n",
    "png('../output/classification_tree_after_pruning_R.png', width = 1200, height = 800)\n",
    "rpart.plot(tree_pruned, \n",
    "           main = paste(\"Classification Tree (After Pruning with α =\", round(optimal_alpha, 6), \")\"),\n",
    "           extra = 104, box.palette = \"RdBu\", shadow.col = \"gray\")\n",
    "dev.off()\n",
    "\n",
    "cat(\"Pruned tree complexity parameters:\\n\")\n",
    "printcp(tree_pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix and Statistics\n",
      "\n",
      "         Actual\n",
      "Predicted  0  1\n",
      "        0 34  5\n",
      "        1 14 36\n",
      "                                          \n",
      "               Accuracy : 0.7865          \n",
      "                 95% CI : (0.6869, 0.8663)\n",
      "    No Information Rate : 0.5393          \n",
      "    P-Value [Acc > NIR] : 1.112e-06       \n",
      "                                          \n",
      "                  Kappa : 0.5771          \n",
      "                                          \n",
      " Mcnemar's Test P-Value : 0.06646         \n",
      "                                          \n",
      "            Sensitivity : 0.7083          \n",
      "            Specificity : 0.8780          \n",
      "         Pos Pred Value : 0.8718          \n",
      "         Neg Pred Value : 0.7200          \n",
      "             Prevalence : 0.5393          \n",
      "         Detection Rate : 0.3820          \n",
      "   Detection Prevalence : 0.4382          \n",
      "      Balanced Accuracy : 0.7932          \n",
      "                                          \n",
      "       'Positive' Class : 0               \n",
      "                                          \n"
     ]
    }
   ],
   "source": [
    "# Make predictions with pruned tree\n",
    "predictions_pruned <- predict(tree_pruned, test_data, type = \"class\")\n",
    "\n",
    "# Calculate confusion matrix for pruned tree\n",
    "cm_pruned <- confusionMatrix(predictions_pruned, test_data$y,\n",
    "                             dnn = c(\"Predicted\", \"Actual\"))\n",
    "print(cm_pruned)\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm_table_pruned <- as.data.frame(cm_pruned$table)\n",
    "colnames(cm_table_pruned) <- c(\"Predicted\", \"Actual\", \"Freq\")\n",
    "cm_table_pruned$Predicted <- ifelse(cm_table_pruned$Predicted == \"0\", \"Does not have HD\", \"Has HD\")\n",
    "cm_table_pruned$Actual <- ifelse(cm_table_pruned$Actual == \"0\", \"Does not have HD\", \"Has HD\")\n",
    "\n",
    "p <- ggplot(cm_table_pruned, aes(x = Predicted, y = Actual, fill = Freq)) +\n",
    "  geom_tile() +\n",
    "  geom_text(aes(label = Freq), size = 8) +\n",
    "  scale_fill_gradient(low = \"white\", high = \"steelblue\") +\n",
    "  labs(title = \"Confusion Matrix (After Pruning)\",\n",
    "       x = \"Predicted Label\", y = \"True Label\") +\n",
    "  theme_minimal() +\n",
    "  theme(text = element_text(size = 14))\n",
    "\n",
    "ggsave('../output/confusion_matrix_after_pruning_R.png', p, width = 8, height = 6, dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:**\n",
    "\n",
    "After implementing cross-validation with pruning using the optimal alpha value:\n",
    "\n",
    "**Cross-Validation Results:**\n",
    "- **Optimal Alpha (cp)**: 0.0001643517 (selected from 50 values ranging from ~4.54e-05 to 0.05)\n",
    "- **Optimal Cross-Validation Accuracy**: 80.77% (from 4-fold cross-validation)\n",
    "\n",
    "**Comparison: Before vs After Pruning:**\n",
    "\n",
    "The pruning process using the optimal alpha value identified through cross-validation shows that:\n",
    "\n",
    "1. **Model Performance**: Both the unpruned and pruned models achieved the same test accuracy of **78.65%**, with identical confusion matrices:\n",
    "   - True Negatives: 34\n",
    "   - True Positives: 36\n",
    "   - False Positives: 14\n",
    "   - False Negatives: 5\n",
    "\n",
    "2. **Why Same Performance?**: This suggests that the optimal alpha value found (0.0001643517) is relatively small, meaning the pruning was minimal. The unpruned tree likely already had reasonable complexity, and the cross-validation confirmed that aggressive pruning wasn't necessary for this dataset.\n",
    "\n",
    "3. **Cross-Validation Benefit**: The cross-validation accuracy (80.77%) is slightly higher than the test accuracy (78.65%), which is expected. The cross-validation process ensures we selected an alpha that generalizes well across different data splits.\n",
    "\n",
    "4. **Key Insights**:\n",
    "   - **Tree Complexity**: The optimal alpha preserves most of the tree structure, indicating the original tree wasn't severely overfitted\n",
    "   - **Generalization**: The consistent performance between models suggests good generalization to unseen data\n",
    "   - **Clinical Relevance**: With 87.80% specificity, the model is effective at identifying heart disease cases, which is crucial for medical screening\n",
    "\n",
    "5. **Model Reliability**: The Kappa statistic of 0.5771 indicates moderate agreement beyond chance, and the balanced accuracy of 79.32% shows the model performs reasonably well across both classes despite some class imbalance.\n",
    "\n",
    "**Conclusion**: The cross-validation process validated that our classification tree has appropriate complexity for this heart disease prediction task, achieving nearly 79% accuracy with good specificity for identifying positive cases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
